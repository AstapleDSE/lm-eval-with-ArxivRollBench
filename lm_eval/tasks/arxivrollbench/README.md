# ğŸš€ ArxivRollBench
*â€œFresh from ArXiv, served once, and never reheated.â€*

> ğŸ“Œ TL;DR: ArxivRollBench tells you **â€œHow much of your score is real, and how much is cheating?â€**  

---

## 1. ğŸ“Š What is ArxivRollBench?

ArxivRollBench is a **dynamic, one-time-pad-inspired evaluation framework** ğŸ›¡ï¸ that **audits** how much Large Language Models (LLMs) **over-estimate** their true abilities on public benchmarks.  

### âš ï¸ Key Problems ArxivRollBench Tackles  
- **ğŸ“¥ Data contamination**  
  Public benchmarks (MMLU, GSM8K, etc.) often sneak into pre-training data â†’ inflated scores.  
- **ğŸ¯ Biased overtraining**  
  Developers may â€œteach to the test,â€ tuning models only on popular domains.  
- **ğŸ•µï¸ Transparency crisis**  
  Private leaderboards (SEAL, Chatbot Arena) are opaque & hard to reproduce.

---

### ğŸ§ª How ArxivRollBench Works  

1. **ğŸŒ± Fresh Test Cases**  
   Every 6 months we scrape **latest ArXiv preprints** (Aprâ€“Sep 2024 â†’ ArxivBench-2024b).  
   > ğŸ·ï¸ Domains: CS, Math, Physics, Bio, Econ, Finance, Statistics, EE.

2. **ğŸ² SCP Tasks**  
   Articles are auto-converted into three symbolic tasks:  
   - **Sequencing** ğŸ”€ â†’ Re-order shuffled sentences.  
   - **Cloze** ğŸ•³ï¸ â†’ Fill masked sentences.  
   - **Prediction** ğŸ”® â†’ Choose the correct next sentence.  

3. **ğŸ“ˆ Rugged Scores (RS)**  
   - **RS-I** ğŸ§ª = % inflation on public vs. private benchmarks.  
   - **RS-II** âš–ï¸ = performance variance across domains (biased training detector).

---

### ğŸŒŸ Unique Features  
- **ğŸ• One-Time Use**: private benchmarks are **used once**, then **expired & open-sourced**.  
- **âœ… High Quality**: filtered for length, complexity, minimal math/tables.  
- **ğŸŒ Broad Coverage**: 8 domains, ~100-word contexts, 1 k+ samples per domain.

---

## ğŸ‘©â€ğŸ’» 2. How Do I Evaluate my Model?

The most easy way is to use `llm-eval-harness`

Just install `lm-eval`.
and then evaluate a huggingface model with:

```sh

	lm_eval\
	    --model hf\
	    --model_args pretrained=your-model-name,parallelize=True\
	    --tasks any-arxivrollbench-task\
	    --verbosity DEBUG\
	    --log_samples\
	    --output_path your-log-path

```
















